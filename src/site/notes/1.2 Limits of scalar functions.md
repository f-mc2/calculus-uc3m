---
{"dg-publish":true,"permalink":"/1-2-limits-of-scalar-functions/","created":"2023-04-24T15:22:21.830+02:00","updated":"2023-07-09T00:14:24.222+02:00"}
---

# Distance and intervals

Let $f:X\rightarrow Y$ be a function. The notion of limit formalizes, rigorously, what happens to the output when the inputs gets closer and closer to a fixed value. Roughly speaking, we write
$$
\lim_{x\rightarrow x_{0}} f(x)=l
$$
meaning that the output $f(x)$ gets closer to $l$ if the input $x$ is closer to $x_{0}$. 

Note that , in general, it is not always true that a limit exists.

In order to make things precise, we first need to understand what we mean when we say that something is closer to a fixed value. In the case of real numbers, if we fix $x_{0}\in \mathbb{R}$, we say that $x_{1}$ is closer than $x_{2}$ if
$$
|x_{1}- x_{0}|\leq |x_{2} - x_{0}|.
$$
If $\leq$ is replaced by $<$, we say it is *strictly smaller*. 

>[!defn] Definition: Distance function
>The two-point function $d\colon \mathbb{R}\times\mathbb{R}\rightarrow\mathbb{R}$ given by
>$$
>d(x,y)=\sqrt{(x-y)^{2}}=|x-y|
>$$
>is referred to as a **distance function** on $\mathbb{R}$.

>[!rem] Remark
>An intuitive reason for $d$ to measure distances follows from our direct experience, for instance with ruled paper (can you guess why/how?),  but there are also more abstract reasons connected with the theory of [metric spaces](https://en.wikipedia.org/wiki/Metric_space).

Besides the notion of distance between real numbers, we need to introduce various types of intervals. These objects help in formalizing the way $x$ approaches $x_{0}$.

>[!defn] Definition: Open and closed intervals
>Given $a,b\in\mathbb{R}$, we introduce  the **open interval** 
>$$
>(a,b):= \{x\in\mathbb{R}\,|\quad a< x < b \},
>$$
>and the closed interval
>$$
>[a,b]:= \{x\in\mathbb{R}\,|\quad a\leq x \leq b \}.
>$$

Intuitively speaking, the interval $(a,b)$ is _open_ because its boundary points **are not** part of it, while $[a,b]$ is _closed_ because its boundary points **are** part of it.
 
Quite obviously, we also have the intervals
$$
[a,b) := \{x\in\mathbb{R}\,|\quad a\leq x < b\}
$$
$$
(a,b] := \{x\in\mathbb{R}\,|\quad a < x \leq b\}, 
$$
which, however, are neither open nor closed.

It will be useful to also consider the **symmetric open interval**

$$ I_{x_{0},\epsilon}\equiv(x_{0}-\epsilon, x_{0}+\epsilon)=\{x\in\mathbb{R}\,|\quad x_{0}-\epsilon < x < x_{0} + \epsilon\} $$

centered at $x_{0}$ with length $2\epsilon$ with $\epsilon>0$. It is not hard to see that if $x\in I_{x_{0},\epsilon}$, then either $x-x_{0}< \epsilon$  or $x_{0} - x <\epsilon$. It then follows that $|x-x_{0}|<\epsilon$, so that

$$ I_{x_{0},\epsilon}=\{x\in\mathbb{R}\,| \quad d(x_{0},x)<\epsilon\}. $$
Therefore, the symmetric open intervals of $\mathbb{R}$ may be determined through the distance function.

Finally, we can also describe unbounded intervals by introducing the formal symbols $+\infty$ and $-\infty$. In this case, we have the open unbounded intervals

$$
\begin{split}
(a,+\infty)&:=\{x\in\mathbb{R}\,|\quad a< x \} \\ &\\ (-\infty,a)&:=\{x\in\mathbb{R}\,|\quad x<a \},
\end{split}
$$

as well as the unbounded intervals

$$
\begin{split}
[a,+\infty)&:=\{x\in\mathbb{R}\,|\quad a\leq x\} \\ &\\ (-\infty,a]&:=\{x\in\mathbb{R}\,|\quad x\leq a\},
\end{split}
$$
which, however, are neither open nor closed.

# Limits of scalar functions

Let us come back to the formal expression
$$
\lim_{x\rightarrow x_{0}} f(x)=l
$$
we want to give meaning to.

The point $x_{0}$ is not arbitrary. It must be an **accumulation point** for the domain of the function $f$.

>[!defn] Definition: Accumulation point
>A point $x_{0}\in \mathbb{R}$ is said to be an **accumulation point** for the domain $D$ of the function $f$ if there is $r>0$ such that the open interval $I_{x_{0},r}$ is contained in $D$ except at most for the point $x_{0}$.

>[!exmp] Examples 
>1) Let $D=(a,b)$, then every $x\in(a,b)$ is an accumulation point.
>2) Let $D=[0,1)\cup(1,2]$, then $1$ is an accumulation point. 
>3) Let $D=[0,1]$, then neither $0$ nor $1$ are accumulation points.

Then, the notion of limit is formalized using the distance function introduced above and two numerical quantifiers, say $\epsilon$ and $\delta$, to explicitly evaluate how close we are to $l$ and $x_{0}$, respectively. 

>[!defn] Definition: Limits with [$(\epsilon,\delta)$](https://en.wikipedia.org/wiki/Limit_of_a_function#(%CE%B5,_%CE%B4)-definition_of_limit)
>Consider the scalar function $f\colon D\subseteq \mathbb{R}\rightarrow \mathbb{R}$, and let $x_{0}$ be an accumulation point for $D$. We say that the formal equality
>$$ 
>\lim_{x\rightarrow x_{0}} f(x)=l 
>$$
>holds if for every $\epsilon>0$ there is a  $0< \delta< r$ such that
>$$
>d(x_{0},x)=|x-x_{0}|<\delta \Longrightarrow d(l,f(x))=|f(x)-l|<\epsilon .
>$$
>When this happens, we say that the limit of $f$, for $x$ going to $x_{0}$, is $l$.
{ #cbf378}


The previous definition is well-posed because the limit, if it exists, is unique.

>[!important] Proposition: Uniqueness of limits
>Consider the scalar function $f\colon D\subseteq\mathbb{R}\rightarrow \mathbb{R}$. If the equalities
>$$
>\lim_{x\rightarrow x_{0}}f(x)=L\quad\mbox{ and }\quad \lim_{x\rightarrow x_{0}}f(x)=M
>$$ 
>hold, then $L=M$.
{ #6fcbc5}


# Properties of limits

The computation of limits through the definition given above is often difficult. As it is customary in mathematics, a set of simple cases is investigated using *educated guesses* (that is, the sophisticated siblings of sheer luck), and then general theorems are proved to help us exploit to the maximum the simple examples solved.

The first type of general results we consider are algebraic manipulations of limits. The following proposition, whose proof is an instructive exercise for the willful reader, essentially states that *the limit of the sum/product/quotient is the sum/product/quotient of the limits*.

To correctly write this proposition, we need to introduce the symbols $\sum$ and $\prod$ which help to condensate the writing of sums and products, respectively. Specifically, we set
$$
\sum\limits_{j=1}^{n} A_{j}\equiv A_{1} + A_{2} + \cdots + A_{n}
$$
$$
\prod_{j=1}^{n}A_{j}=A_{1}\,A_{2}\,\cdots\,A_{n} ,
$$
where $(A_{1},\cdots,A_{n})$ can be a finite sequence of numbers or functions.

>[!important] Proposition: Algebraic manipulations of limits
>Let $x_{0}\in\mathbb{R}$, $(\alpha_{1},\cdots\alpha_{n})$ be a finite sequence of real numbers, and $(f_{1},\cdots,f_{n})$ a finite sequence of scalar functions. Suppose that
>$$
>\lim_{x\rightarrow x_{0}}f_{j}(x)=L_{j}\in \mathbb{R}
>$$
>for every $j=1,...,n$. Then, it holds
>
>$$
>\begin{split}
>1)\quad & \lim_{x\rightarrow x_{0}} \sum_{j=1}^{n}\,\alpha_{j}\,f_{j}(x) =\sum_{j=1}^{n}\,\lim_{x\rightarrow x_{0}} \left(\alpha_{j}\,f_{j}(x)\right) = \sum_{j=1}^{n}\,\alpha_{j}\,L_{j} \\ & \\
>2) \quad &\lim_{x\rightarrow x_{0}}\prod_{j=1}^{n} \,\alpha_{j}\,f_{j}(x) =\prod_{j=1}^{n}\,\lim_{x\rightarrow x_{0}} \left(\alpha_{j}\,f_{j}(x)\right) = \prod_{j=1}^{n}\,\alpha_{j}\,L_{j} .
>\end{split}
>$$
>
>Moreover, if $n=2$ and $\alpha_{2},L_{2}\neq 0$, it holds
>$$
>\lim_{x\rightarrow x_{0}}\,\frac{\alpha_{1}f_{1}(x)}{\alpha_{2}f_{2}(x)}=\frac{\alpha_{1}L_{1}}{\alpha_{2} L_{2}}.
>$$
{ #f50bb0}


The next theorem is of paramount importance, and is known to humans by many names (very much like the [Many-Faced God](https://gameofthrones.fandom.com/wiki/Many-Faced_God)). Informally speaking, the underlying idea behind the theorem is that, if a function $f$ lies between two other functions, say $g$ and $h$, the limits of $f$  are determined by the limits of $g$ and $h$.

>[!important] Theorem: Squeeze (pinching) theorem
> Let $f,g,h$ be scalar functions with the same domain $D$, and let $x_{0}$ be an accumulation point for $D$. If $h(x)\leq f(x)\leq g(x)$ for all $x\in D$ and 
> $$
> \lim_{x\rightarrow x_{0}}h(x)=\lim_{x\rightarrow x_{0}}g(x)=L\in\mathbb{R},
> $$
> then it follows that
> $$
> \lim_{x\rightarrow x_{0}}f(x)=L.
> $$
{ #ec717d}


Next is a proposition that regulates how limits behave with respect to composition of functions. 

>[!important] Proposition: Limit of composite functions
>Consider the scalar functions $f$ and $g$ such that
>$$
>\lim_{y\rightarrow l} f(y) =L , \qquad  \lim_{x\rightarrow x_{0}}g(x) = l.
>$$ 
>If there is no open interval containing $x_{0}$ on which $g(x)$ is constantly equal to $l$, then it follows that
>$$
>\lim_{x\rightarrow x_{0}} f\circ g(x)=L
>$$

A useful corollary is obtained when $g(x)= x_{0} + x$.

>[!important] Proposition
>
> Consider the scalar function $f$ with domain $D$, and the accumulation point $x_{0}$. Then, it follows that 
> $$
> \lim_{x\rightarrow x_{0}}f(x)=L \quad \Longleftrightarrow \quad \lim_{h\rightarrow 0}f(x_{0}+h)=L .
> $$

# Continuity at a point

If the accumulation point $x_{0}$ is also part of the domain of the function $f$, it may happen that 
$$
\lim_{x\rightarrow x_{0}}f(x)=l=f(x_{0}) .
$$
Functions of this type are particularly important in mathematics and its applications.

>[!defn] Definition: Continuity at a point
>
>The function $f\colon D\subseteq \mathbb{R}\rightarrow \mathbb{R}$ is said to be **continuous** at $x_{0}\in D$ if
>$$
>\lim_{x\rightarrow x_{0}}f(x)=f(x_{0}).
>$$

Just as there is an algebra of limits, there is an algebra of continuous functions.

>[!important] Proposition: Algebraic manipulations of continuous functions
>
>Let  $(\alpha_{1},\cdots\alpha_{n})$ be a finite sequence of real numbers, and $(f_{1},\cdots,f_{n})$ a finite sequence of scalar functions which are all continuous at $x_{0}$. Then, it follows that 
>$$
>F(x)=\sum\limits_{j=1}^{n}\alpha_{j}f_{j}(x),\qquad G(x)=\prod_{j=1}^{n}\alpha_{j}f_{j}(x)
>$$ 
>are continuous at $x_{0}$. Moreover, when $n=2$ and  $\alpha_{2}f_{2}(x_{0})\neq 0$,  it follows that
>$$
>H(x)=\frac{\alpha_{1}f_{1}(x)}{\alpha_{2}f_{2}(x)}
>$$
>is continuous at $x_{0}$.

Moreover, continuous functions behaves well with respect to composition of functions.

>[!important] Proposition: Composition of continuous functions
>Let $g$ be continuous at $x_{0}$ and $f$ be continuous at $g(x_{0})$. Then, the composite function $f\circ g$ is continuous at $x_{0}$. In particular, if $f$ is invertible and continuous on an open interval $I$ then its inverse $f^{-1}$ is also continuous.

>[!rem] Remark
>While the composition of continuous functions is continuous, it is not true that a continuous composite functions is the composition of continuous functions. Indeed, take
>
>$$
>f(x)=g(x)= \left\{\begin{matrix} \frac{1}{x} & \mbox{ if } x\neq 0 \\ 0 & \mbox{ if } x = 0\end{matrix}\right.
>$$
>
>As we will be able to appreciate once we introduce [[1.3 One-sided limits of scalar functions\|*one-sided*]] and *improper limits*, these functions have an essential discontinuity at $x=0$. However, the composite function $f\circ g$ reads
>$$
>f\circ g(x) = x
>$$
>which is clearly continuous for every $x\in\mathbb{R}$.

# Left/right limits 

Let us consider the function $f\colon [0,1]\rightarrow \mathbb{R}$ with $f(x)=x^{2}$. We should be able to see that $f$ is [[1.2 Limits of scalar functions#Continuous functions\|continuous]] for every $x\in(0,1)$, but the behavior of $f$ at the boundary points $0,1$ can not be investigated using the notion of [[1.2 Limits of scalar functions#Limits of scalar functions\|limit]] we introduced. 

```desmos-graph
left=-1; right=2;
top=2; bottom=-1;
---
f(x)=x^{2}
```

However, if we compute $f(x)$ for input values which are closer and closer to $x=0$, we obtain output values which are closer and closer to $f(0)=0$ (and similarly for $x=1$), and we are thus tempted to say that $f$ has a limit for $x$ going to $0$ (or $1$). Luckily, there is a machinery that helps us making rigorous this empirical observation, and thus extends the notion of limit.

>[!defn] Definition: Left/right accumulation point
>A point $x_{0}\in \mathbb{R}$ is said to be a **left accumulation point** for the domain $D$ of the function $f$ if there is $r>0$ such that the open interval $(x_{0},r)$ is contained in $D$. A **right accumulation point** is then defined in the obvious way.

>[!exmp] Examples 
>1) Let $D=(a,b)$, then every $x\in(a,b)$ is both a left and right accumulation point.
>2) Let $D=[0,1]$, then $0$ is a right accumulation point and $1$ is a left accumulation point.

The intuition behind the notion of left/right limit is that of splitting in two the definition of limit using $(\epsilon,\delta)$ given [[1.2 Limits of scalar functions#^cbf378\|before]] depending on how $x$ reaches $x_{0}$.

>[!note] Definition: [Left/right limits](https://en.wikipedia.org/wiki/One-sided_limit)
>Consider the function $f\colon D\subseteq \mathbb{R}\rightarrow \mathbb{R}$ and the **left accumulation point** $x_{0}$ for $D$. We say that the formal equality  
>$$
>\lim_{x\rightarrow x_{0}^{+}} f(x)=l
>$$  
>holds if for every $\epsilon>0$ there is a  $0< \delta< r$ such that
>$$ 
>d(x_{0},x)=|x-x_{0}|<\delta \Longrightarrow d(l,f(x))=|f(x)-l|<\epsilon 
>$$
>whenever $x_{0}<x$. In this case, we say that $l$ is the right limit of $f$ for $x$ going to $x_{0}$ from the right.
> Similarly, if $x_{0}$ is a **right accumulation point**, we say that the formal equality  
>$$
>\lim_{x\rightarrow x_{0}^{-}} f(x)=l
>$$  
>holds if for every $\epsilon>0$ there is a  $0< \delta< r$ such that
>$$ 
>d(x_{0},x)=|x-x_{0}|<\delta \Longrightarrow d(l,f(x))=|f(x)-l|<\epsilon 
>$$
>whenever $x<x_{0}$. In this case, we say that $l$ is the left limit of $f$ for $x$ going to $x_{0}$ from the **left**.

>[!rem] Remark
>Note that the [[1.2 Limits of scalar functions#^6fcbc5\|uniqueness]], the [[1.2 Limits of scalar functions#^f50bb0\|algebraic manipulations]], and the [[1.2 Limits of scalar functions#^ec717d\|squeeze (pinching) theorem]] can be formulated to hold also for **left/right limits**.

Ordinary limits and left/right limits are related to one another according to the following proposition (whose proof is an instructive exercise).

>[!important] Proposition
>Given a function $f\colon D\rightarrow\mathbb{R}$, and an accumulation point $x_{0}$ for $D$, we have that 
>$$
>\lim_{x\rightarrow x_{0}}f(x)=l
>$$
>**if and only if**
>$$
>\lim_{x\rightarrow x_{0}^{+}}f(x)=\lim_{x\rightarrow x_{0}^{-}}f(x)=l .
>$$ 

Left/right limits are particularly useful when dealing with step-wise defined functions. 

# Left/right continuity

Coming back to $f\colon [0,1]\rightarrow\mathbb{R}$ with $f(x)=x^{2}$, we are now able to prove that
$$
\lim_{x\rightarrow 0^{+}}f(x)=0, \quad \mbox{ and } \quad \lim_{x\rightarrow 1^{-}}f(x)=1 .
$$
However, we can not help but notice that $f(0)=0$ and $f(1)=1$ so that our function seems to have a property like [[1.2 Limits of scalar functions#Continuous functions\|continuous function]] also at the boundary points $0$ and $1$. Accordingly, we can introduce the notion of left/right continuity to describe this situation.

>[!defn] Definition: Left/right continuity at a point
>The function $f\colon D\subseteq \mathbb{R}\rightarrow \mathbb{R}$ is said to be **left continuous** at $x_{0}\in D$ if
>$$
>\lim_{x\rightarrow x_{0}^{-}}f(x)=f(x_{0}).
>$$
>Right continuity is defined in the obvious way. 

>[!important] Proposition
>Let $f\colon D\rightarrow\mathbb{R}$. Then $f$ is continuous at $x_{0}\in D$ **if and only if** it is both left and right continuous at $x_{0}$.

# Continuous functions

When exploited together, continuity and left/right continuity at a point allow to introduce the notion of **continuous function**, which I personally believe to be an incredibly powerful concept of modern mathematics. From an intuitive point of view, a scalar function is **continuous** if its graph can be drawn without lifting the pen/pencil from the paper, that is, in a *continuous* way.

>[!defn] Definition: Continuous functions
>The function $f\colon D\subseteq \mathbb{R}\rightarrow \mathbb{R}$ said to be continuous if it is continuous at all accumulation points $x_{0}\in D$, and left/right continuous at all right/left accumulation points $x_{0}\in D$.

Two reasons why continuous functions are tremendously useful in applications are contained in the following theorems.

>[!important] Theorem: [intermediate value theorem](https://en.wikipedia.org/wiki/Intermediate_value_theorem)
>If $f$ is continuos in $[a,b]$ and $K$ is any number between $f(a)$ and $f(b)$, then there is at least one point $c\in (a,b)$ such that $f(c)=K$.
>

>[!important] Theorem ([Extreme value theorem](https://en.wikipedia.org/wiki/Extreme_value_theorem))
>If $f$ is continuous in $[a,b]$ then it attains a maximum and minimum value in $[a,b]$.

# Improper limits


# Discontinuities


# End