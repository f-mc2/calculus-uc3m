---
{"dg-publish":true,"permalink":"/1-7-exercises/","created":"2023-07-02T17:05:44.464+02:00","updated":"2023-09-12T11:20:07.684+02:00"}
---

# 1 Limits of scalar functions



1) Compute 
	$$ \lim_{x\rightarrow x_{0}} f(x)= f(x_{0}) $$
	for $f(x)=c$, $f(x)=x$, and $f(x)=x^{2}$.  
	>[!note]- Solution 
	>Let us start considering the constant function $f(x)=c$ with $x\in\mathbb{R}$, and prove that
	>	$$ \lim_{x\rightarrow x_{0}} f(x)= f(x_{0}). $$ 
	> Indeed, it immediately follows that $|f(x) - f(x_{0})|=0<\epsilon$ for every $x\in\mathbb{R}$ and every $\epsilon>0$.  Now, let us consider the function $f(x)=x$, and prove that 
	> 	$$ \lim_{x\rightarrow x_{0}} f(x)= f(x_{0}). $$ 
	> Again, it is immediate to check that $|f(x) - f(x_{0})|=|x - x_{0}|$, and thus, taking $\delta_{\epsilon}< \epsilon$, we get that $|x - x_{0}|<\delta_{\epsilon}$ implies $|f(x) - f(x_{0})|<\epsilon$ Finally, let us consider the function $f(x)=x^{2}$, and prove that 
	> $$ \lim_{x\rightarrow x_{0}} f(x)= f(x_{0}) $$ 
	> for every $x_{0}\in\mathbb{R}$.  We have 
	> $$ |x^{2} - x_{0}^{2}| =|(x+x_{0})(x-x_{0})|\leq (|x| + |x_{0}|)|x-x_{0}| . $$ 
	> Recall that we must check that $|f(x) - f(x_{0})|< \epsilon$ whenever $|x - x_{0}|<\delta$, with $\delta>0$ to be determined depending on $\epsilon>0$.  A direct computation shows that 
	> $$ | x+ x_{0}| =|x - x_{0} + 2x_{0}|\leq |x - x_{0}| + 2|x_{0}| $$ 
	> so that 
	> $$ |x^{2} - x_{0}^{2}|\leq (|x - x_{0}| + 2|x_{0}|)\,|x-x_{0}| < (2|x_{0}| + \delta_{\epsilon})\,\delta_{\epsilon}. $$
	> Therefore, if 
	> $$ \delta_{\epsilon}^{2} + 2|x_{0}| \delta_{\epsilon} - \epsilon>0 $$ 
	> we are done. By solving the previous [quadratic equation](https://en.wikipedia.org/wiki/Quadratic_equation) in the variable $\delta_{\epsilon}$ we obtain the condition 
	> $$ 0 < \delta_{\epsilon} <  \sqrt{x^{2}_{0} + \epsilon} -|x_{0}| = \sqrt{x^{2}_{0} + \epsilon} - \sqrt{x^{2}_{0}}. $$

2)  Using previous results and [[1.2 Limits of scalar functions#^f50bb0\|algebraic manipulations of limits]], check that every polynomial function is continuous.

3) Use the [[1.2 Limits of scalar functions#Improper limits\|definition]] to check the following limits: 
	$$ \begin{split} 1) \quad & \lim_{x\rightarrow +\infty}\,x^{n}=+\infty \\ & \\ 2) \quad & \lim_{x\rightarrow -\infty}\,x^{2n}=+\infty \\ & \\ 3) \quad & \lim_{x\rightarrow -\infty}\,x^{2n+1}=-\infty \\ & \\ 4) \quad & \lim_{x\rightarrow 0^{\pm}} \;\frac{1}{x^{2n}} =+ \infty \\& \\ 5) \quad & \lim_{x\rightarrow 0^{\pm}} \;\frac{1}{x^{2n+1}} =\pm \infty \\& \\ 	6)   \quad & \lim_{x\rightarrow \pm\infty} \;\frac{1}{x^{n}} =0 \\& \\ \end{split} $$
	>[!note]- Solution 
	>1) We must prove that, for every $K>0$, there is $M>0$ such that $x>M$ implies $f(x)=x^{n}>K$. Taking $M=\sqrt[n]{K}$, we have $f(x)=x^{n}> M^{n}=K$ as requested.
	>2) We must prove that, for every $K>0$, there is $M>0$ such that $x<-M$ implies $f(x)=x^{2n}>K$. Note that, even if $x<0$, it is $f(x)=x^{2n}>0$, so that $f(x)=x^{2n}>M^{2n}$. Taking $M=\sqrt[2n]{K}$, we have $f(x)=x^{2n}>M^{2n}=K$ as requested.
	>3) We must prove that, for every $K>0$, there is $M>0$ such that $x<-M$ implies $f(x)=x^{2n+1}<-K$. Note that $f(x)=x^{2n+1}<0$ when $x<0$, so that $f(x)=x^{2n+1}<-M^{2n+1}$. Taking $M=\sqrt[2n+1]{K}$, we have $f(x)=x^{2n+1}<-M^{2n+1}=-K$ as requested.
	>4) For the right limit ($0^{+}$), we must prove that, for every $K>0$, there is $\delta>0$ such that $x<\delta$ implies $f(x)>K$. If $x<\delta$, then $\frac{1}{\delta}<\frac{1}{x}$, which means $\frac{1}{\delta^{2n}}<\frac{1}{x^{2n}}$. Taking $\delta=\frac{1}{\sqrt[2n]{K}}$, we have $f(x)=\frac{1}{x^{2n}}>\frac{1}{\delta^{2n}}=K$ as requested. For the left limit ($0^{-}$), we must prove that, for every $K>0$, there is $\delta>0$ such that $|x|<\delta$ implies $f(x)>K$. Recall that $x^{2n}>0$ even if $x<0$. If $|x|<\delta$, then $\frac{1}{\delta}<\frac{1}{|x|}$, which means $\frac{1}{\delta^{2n}}<\frac{1}{x^{2n}}$. Taking $\delta=\frac{1}{\sqrt[2n]{K}}$, we have $f(x)=\frac{1}{x^{2n}}>\frac{1}{\delta^{2n}}=K$ as requested.
	>5) For the right limit ($0^{+}$), we must prove that, for every $K>0$, there is $\delta>0$ such that $x<\delta$ implies $f(x)>K$. If $x<\delta$, then $\frac{1}{\delta}<\frac{1}{x}$, which means $\frac{1}{\delta^{2n+1}}<\frac{1}{x^{2n+1}}$. Taking $\delta=\frac{1}{\sqrt[2n+1]{K}}$, we have $f(x)=\frac{1}{x^{2n+1}}>\frac{1}{\delta^{2n}}=K$ as requested. For the left limit ($0^{-}$), we must prove that, for every $K>0$, there is $\delta>0$ such that $|x|<\delta$ implies $f(x)<-K$, which is equivalent to $|f(x)|>K$. Recall that $x^{2n+1}<0$ when $x<0$. If $|x|<\delta$, then $\frac{1}{\delta}<\frac{1}{|x|}$, which means $\frac{1}{\delta^{2n+1}}<\frac{1}{|x^{2n+1}|}$. Taking $\delta=\frac{1}{\sqrt[2n+1]{K}}$, we have $|f(x)|=\frac{1}{|x^{2n+1}|}>\frac{1}{\delta^{2n+1}}=K$ as requested.
	>6) For $x\rightarrow+\infty$, we must prove that, for every $\epsilon>0$, there is $M>0$ such that $x>M$ implies $|f(x) - 0|<\epsilon$. If $x>M>0$, then $|f(x)|=|\frac{1}{x^{n}}|=\frac{1}{x^{n}}<\frac{1}{M^{n}}$, so that $M>\frac{1}{\sqrt[n]{\epsilon}}$ does the job. For $x\rightarrow-\infty$, we must prove that, for every $\epsilon>0$, there is $M>0$ such that $x<-M$ implies $|f(x)-0|<\epsilon$. If $x<-M<0$ then $|x|>M$ so that $|f(x)|=\frac{1}{|x^{n}|}<\frac{1}{M^{n}}$, and thus $M>\frac{1}{\sqrt[n]{\epsilon}}$ does the job.

4) Consider the function $([0,+\infty),\mathbb{R},f,\mathbb{R})$, where $f(x)=x^{\frac{1}{n}}\equiv\sqrt[n]{x}$ with $n>1$: 
	1) prove it is a continuous function;
	2) find its limit at $+\infty$;
	3) what can we say regarding $f(x)=x^{\frac{m}{n}}$? 
	
	>[!note]- Solution 
	>1) We start noting that $([0,+\infty),\mathbb{R},f,\mathbb{R})$ is the [[1.1 Sets and functions#^ac035a\|inverse function]] of $([0,+\infty),\mathbb{R},g,\mathbb{R})$ where $g(y)=y^{n}$.  In exercise 2) above, we proved that $([0,+\infty),\mathbb{R},g,\mathbb{R})$ is continuous. Therefore, [[1.2 Limits of scalar functions#^0478fa\|its inverse is also continuous]]. 
	>2) We note that $1<M<x$ implies $1<\sqrt[n]{M}<\sqrt[n]{x}$, so that $M=K^{n}$ implies $x^{\frac{1}{n}}>K$,  which means that  $\lim_{x\rightarrow+\infty}f(x)=+\infty$. 
	>3) Once we know $([0,+\infty),\mathbb{R},f,\mathbb{R})$ is continuous, we can use the [[1.2 Limits of scalar functions#^47f720\|algebra of continuous functions]] to conclude $([0,+\infty),\mathbb{R},h,\mathbb{R})$, where $h(x)=x^{\frac{m}{n}}$, is continuous too.
5) Check the following limits: 
	$$ \begin{split} 1) \quad & \lim_{x\rightarrow 1}\,\frac{x}{x+1}=\frac{1}{2}  \\ & \\ 2) \quad &  \lim_{x\rightarrow 0}\, \frac{x}{|x|}=\nexists \\ & \\ 3) \quad &  \lim_{x\rightarrow 0}\, \frac{|x|}{ x }=\nexists \\ & \\ 4) \quad &  \lim_{x\rightarrow 0}\, f(x) =\nexists \quad \mbox{ with } f(x)= \left\{\begin{matrix} 1-x^{2} & \mbox{ if } x<0 \\ x^{3} & \mbox{ if } x\geq 0\end{matrix}\right.  \\ & \\ 5) \quad &  \lim_{x\rightarrow 1^{\pm}}\, \frac{x^{2}-1}{ x^{2} -2x + 1 }= \pm\infty\\ & \\ 6) \quad &  \lim_{x\rightarrow 2^{+}}\, \frac{\sqrt{x^{2} -4}}{x-2} = +\infty \end{split} $$
	>[!note]- Solution
	>1) Use [[1.2 Limits of scalar functions#^f50bb0\|algebraic manipulation of limits]].
	>2) When $x\rightarrow 0^{+}$, it is $\frac{x}{|x|}=1$, while $\frac{x}{|x|}=-1$ when $x\rightarrow 0^{-}$. Consequently, the left and right limits are different, and the limit for $x\rightarrow 0$ does not exist.
	>3) The proof is analogous to that of 2) above. 
	>4) The proof is analogous to that of 2) above.
	>5) When $x=1$, both numerator and denominator vanish, and we get an indeterminate form. However, the fact that both polynomials have a common root ($x=1$) suggests we [factorize them](https://en.wikipedia.org/wiki/Polynomial#Factoring). In particular, we have $x^{2}-1=(x-1)(x+1)$, and $x^{2}-2x +1=(x-1)(x-1)$. Consequently, we have 
	>		$$ \frac{x^{2}-1}{x^{2}-2x+1}=\frac{x+1}{x-1}=1+ \frac{2}{x-1}. $$ 
	>		To check the right limit, we need to show that, for every $K>0$, there is $\delta>0$ such that  $0<x-1<\delta$ implies $|1+\frac{2}{x-1}|>K$. Now, $0<x-1<\delta$ implies $\frac{1}{\delta}<\frac{1}{x-1}$, and  $1+\frac{2}{x-1}>0$, so that $|1+\frac{2}{x-1}|=1+\frac{2}{x-1}>1+ \frac{2}{\delta}>K$ provided $\delta<\frac{2}{K-1}$. The left limit is found proceeding in analogy.
	>6) Following the reasoning in point 5), we obtain 
	>		$$ \frac{\sqrt{x^{2}-4}}{x-2}=\sqrt{1+\frac{4}{x-2}}. $$
	>		Then, to check the right limit, we need to show that, for every $K>0$, there is $\delta>0$ such that  $0<x-2<\delta$ implies $|f(x)|=\sqrt{1+\frac{4}{x-2}}>K$. Since $1+\frac{4}{x-2}>0$ when $0<x-2$, the inequality $|f(x)|=\sqrt{1+\frac{4}{x-2}}>K$ is equivalent to $1+\frac{4}{x-2}>K^{2}$. Now, $0<x-2<\delta$ implies $\frac{1}{x-2}>\frac{1}{\delta}$, so that $1+\frac{4}{x-2}>1+ \frac{4}{\delta}>K^{2}$ provided $\delta<\frac{4}{K^{2}-1}$.




# 2 Derivatives 



1) Find the derivative of  $f(x)=x^{3}$ and $f(x)=x^{4}$ for every $x_{0}\in\mathbb{R}$.  **Hint**: Use  [Newton's binomial formula](https://en.wikipedia.org/wiki/Binomial_theorem)
	$$ (a+b)^{n}=\sum\limits_{k=0}^{n}{n\choose k} a^{n-k}b^{k}=\sum\limits_{k=0}^{n}{n\choose k} a^{k}b^{n-k}, $$
		where ${n\choose k}=\frac{n!}{k!(n-k)!}$ is the [binomial coefficient](https://en.wikipedia.org/wiki/Binomial_coefficient) counting the ways of choosing an (unordered) subset of $k$ elements from a fixed set of $n$ elements, to check that $\frac{\mathrm{d}f}{dx}=n\, x^{n-1}$ for $f(x)=x^{n}$ and all $n>0$ in $\mathbb{N}$.

2) Compute the derivative of $([0,+\infty),\mathbb{R},f,\mathbb{R})$, where $f(x)=\sqrt[n]{x}=x^{\frac{1}{n}}$ with $n>1$, at each point.
	 >[!note]- Solution 
	 >A direct computation shows that $([0,+\infty),\mathbb{R},f,\mathbb{R})$ is the inverse function of $([0,+\infty),\mathbb{R},g,\mathbb{R})$ with $g(y)=y^{n}$. The function $([0,+\infty),\mathbb{R},g,\mathbb{R})$ is differentiable for every $y>0$. Therefore, [[1.3 Derivatives of scalar functions#^05d051\|we conclude that]] $([0,+\infty),\mathbb{R},f,\mathbb{R})$ is differentiable for each $x>0$, and its derivative reads 
	 >$$ f'(x)=\frac{1}{n} x^{\frac{1}{n}-1}. $$
	 >At $y=0$, we can only compute the right derivative of $([0,+\infty),\mathbb{R},g,\mathbb{R})$ . It turns out this derivative vanishes, and thus $([0,+\infty),\mathbb{R},f,\mathbb{R})$ has no right derivative at $x=0$.

3) Determine for which $x\in\mathbb{R}$ the function $(\mathbb{R},\mathbb{R},f,\mathbb{R})$ is differentiable in the following cases: 
	$$ \begin{split} 	1) \quad & f(x)= |x - 2| \\ & \\ 2) \quad & f(x)= \sqrt{|x|} \\ & \\ 			3) \quad & f(x)= \left\{\begin{matrix}  x^{2} & \mbox{ if } x\leq 1 \\ 2-x & \mbox{ if } x> 1\end{matrix}\right. \\ & \\ 	4) \quad & f(x)= \left\{\begin{matrix} x^{2} -1 & \mbox{ if } x\leq 2 \\  3 & \mbox{ if } x> 2\end{matrix}\right. \\ & \\ 	5) \quad & f(x)= \left\{\begin{matrix}  4x & \mbox{ if } x<1 \\ 2x +2 & \mbox{ if } x\geq 1\end{matrix}\right. \\ & \\ 	6) \quad & f(x)= \left\{\begin{matrix}  \frac{-x^{2}}{2}  & \mbox{ if } x<3 \\ -3x & \mbox{ if } x\geq 3\end{matrix}\right. \end{split} $$
	>[!note]- Solution
	>1) Given the appearance of the absolute value, we split our function in two pieces: $([2,\infty),\mathbb{R},f_{1},\mathbb{R})$ with $f_{1}(x)=x-2=f(x)$, and $((-\infty,2],\mathbb{R},f,\mathbb{R})$, with $f_{2}(x)=2-x=f(x)$. Since we already know the derivative of constant and linear functions, and since we have  behave  Note that the function $((2,\infty),\mathbb{R},f_{1},\mathbb{R})$, with $f_{1}(x)=x-2=f(x)$, the [[1.3 Derivatives of scalar functions#^5d20ad\|algebraic manipulations of derivatives]] ensure $([2,\infty),\mathbb{R},f_{1},\mathbb{R})$ is differentiable for every $x>2$, and its right derivative at $x=2$ is equal to 1. Proceeding analogously for $((-\infty,2],\mathbb{R},f,\mathbb{R})$, with $f_{2}(x)=2-x=f(x)$, we obtain it is differentiable for every $x<2$, and its left derivative at $x=2$ is $-1$. We thus conclude that $(\mathbb{R},\mathbb{R},f,\mathbb{R})$ is differentiable everywhere except at $x=2$.
	>2) Following the idea used in point 1), we split the function in two pieces: $([0,\infty),\mathbb{R},f_{1},\mathbb{R})$ with $f_{1}(x)=\sqrt{x}=f(x)$, and $((-\infty,0],\mathbb{R},f,\mathbb{R})$, with $f_{2}(x)=\sqrt{-x}=f(x)$. 
	>3) Following the idea used in point 1) we conclude the function is differentiable for every $x\neq 1$.
	>4) Following the idea used in point 1) we conclude the function is differentiable for every $x\neq 2$.
	>5) Following the idea used in point 1) we conclude the function is differentiable for every $x\neq 1$.
	>6) Following the idea used in point 1) we conclude the function is differentiable everywhere.

4) Whenever possible, compute the derivatives at all points in the maximal domain of the scalar functions determined by:
	$$ \begin{split} 1) \quad &  f(x)= x^{\frac{m}{n}}  \\  & \\5) \quad &  f(x)= \frac{2x}{1-x}  \\  & \\ 3) \quad &  f(x)=\frac{x}{1-x}\,\frac{2-x}{3+x}  \\  & \\ 4) \quad &  f(x)=\frac{(x^{2} +1)^{3}}{x+3}   \\  & \\ 5) \quad &  f(x)=\sqrt{x^{4} + 3x^{2} -2}  \\  & \\ 6) \quad &  f(x)=\sqrt{\frac{x +2}{x^{2}}}  \\  & \\ 7) \quad &  f(x)=\frac{x}{\sqrt{x+2}}  \\  & \\ 8) \quad &    f(x)=(g(x))^{\frac{m}{n}} \end{split} $$
	>[!note]- Solution
	>1) The maximal domain is $[0,+\infty)$. Using the result of exercise 2.2) above together with the [[1.3 Derivatives of scalar functions#^c87d27\|chain rule]], we obtain $f'(x)=\frac{m}{n}x^{\frac{m}{n}-1}$ for every $x>0$, and the right derivative at $x=0$ is $0$ when $m\geq n$, and undefined when $m<n$.
	>2) The maximal domain is $(-\infty,1)\cup (1,+\infty)$. Using the [[1.3 Derivatives of scalar functions#^5d20ad\|algebraic manipulation of derivatives]] we obtain $f'(x)=\frac{2}{(1-x)^{2}}.$
	>3) The maximal domain is $(-\infty,-3)\cup(-3,1)\cup(1,+\infty)$. The derivative is then computed using the [[1.3 Derivatives of scalar functions#^5d20ad\|algebraic manipulation of derivatives]]. You can check your result [here](https://onsolver.com/ ), or look in the [[Home#Tools to help with exercises\|home]] for further suggestions.
	>4) The maximal domain is $(-\infty,-3)\cup(-3,+\infty)$. The derivative is then computed using the [[1.3 Derivatives of scalar functions#^5d20ad\|algebraic manipulation of derivatives]]. You can check your result [here](https://onsolver.com/ ), or look in the [[Home#Tools to help with exercises\|home]] for further suggestions.
	>5) The maximal domain is the subset on which $x^{4}+3x^{2}-2\geq 0$. The derivative is then computed using the [[1.3 Derivatives of scalar functions#^5d20ad\|algebraic manipulation of derivatives]]. You can check your result [here](https://onsolver.com/ ), or look in the [[Home#Tools to help with exercises\|home]] for further suggestions.
	>6) The maximal domain is $[-2,0)\cup(0,+\infty)$. The right derivative at $x=-2$ does not exist, while the derivative in the other points is computed using the [[1.3 Derivatives of scalar functions#^5d20ad\|algebraic manipulation of derivatives]]. You can check your result [here](https://onsolver.com/ ), or look in the [[Home#Tools to help with exercises\|home]] for further suggestions.
	>7) The maximal domain is $(-2,+\infty)$. The derivative is then computed using the [[1.3 Derivatives of scalar functions#^5d20ad\|algebraic manipulation of derivatives]]. You can check your result [here](https://onsolver.com/ ), or look in the [[Home#Tools to help with exercises\|home]] for further suggestions.
	>8) The maximal domain here is the subset on which $g(x)\geq 0$. Then, we can use the [[1.3 Derivatives of scalar functions#^c87d27\|chain rule]] to get 
	>	$$ f'(x)=\frac{m}{n}(g(x))^{\frac{m}{n}-1}\,g'(x) $$
	>			at all those $x$ at which $g$ is differentiable and such that $g(x)>0$. When $g$ is differentiable but $g(x)=0$, the right derivative is undefined when $m<n$ and equal to $0$ when $m\geq n$. Obviously, at all those points at which $g$ is not differentiable, then $f$ is not differentiable.




# 3 Numerical sequences and series



1) Prove the following limits 
	$$ \begin{split} 1) \quad & \lim_{n\rightarrow+\infty}\, n!= + \infty \\ & \\ 	2) \quad &  \lim_{n\rightarrow+\infty}\,\frac{x^{n}}{n!}=0\quad\mbox{ for }\quad |x|\leq 1    \\ & \\	3) \quad &  \lim_{n\rightarrow +\infty}\,\sqrt[n]{n}=1  \\ & \\ 	4) \quad & \lim_{n\rightarrow + \infty}\, \sqrt[n]{n!} = +\infty  \\ & \\ 	5) \quad & \lim_{n\rightarrow +\infty}\,kx^{k+2}-(k+1)x^{k+1}=\left\{\begin{matrix}0 &\mbox{ if } |x|<1 \\ +\infty & \mbox{ if } x>1 \\ \nexists & \mbox{ if } x<-1\end{matrix}\right.     \end{split} $$
	>[!note]- Solution
	>1) Because of the factorial, we can not rely on limits of functions. We must prove that, for every $K>0$, there exists $N\in\mathbb{N}$ such that $a_{n}=n!>K$ for all $n>N$. When $n>1$, it holds $n!=n(n-1)\cdots 1> n$, so that, setting $n=N>K$, we get $a_{n}=n!>n>K$ as desired.
	>2) For $|x|\leq 1$, the sequence $a_{n}=x^{n}$ has limit either $0$ or $1$ (only when $x=\pm1$). Therefore, exploiting the result of point 1) together with the algebraic manipulations of limits of sequences, the desired result follows.   
	>3) Set $b_{n}\equiv \sqrt[n]{n} -1>0$, so that $n=(1+b_{n})^{n}$. Recalling [Newton's binomial formula](https://en.wikipedia.org/wiki/Binomial_theorem)
	>		$$ (a+b)^{n}=\sum\limits_{k=0}^{n}{n\choose k} a^{n-k}b^{k}=\sum\limits_{k=0}^{n}{n\choose k} a^{k}b^{n-k}, $$ 
	>		it follows that 
	>		$$ n=(1+b_{n})^{n}=\sum\limits_{k=0}^{n}{n\choose k} 1^{k}b_{n}^{n-k}\,\stackrel{k=n-2}{\geq}\, \frac{n(n-1)}{2!}b_{n}^{2}, $$ 
	>		which means that $0\leq b_{n}\leq\sqrt{\frac{2}{(n-1)}}$. The squeeze theorem for sequences then implies 
	>		$$ \lim_{n\rightarrow+\infty} b_{n}=0\;\Longleftrightarrow\; \lim_{n\rightarrow+\infty} \sqrt[n]{n}-1=0 ,$$ 
	>		which proves the desired equality.
	>4) Since $n!=n(n-1)\cdots 2\cdot 1)$,  it holds $n!\geq (\sqrt{\frac{n}{2}})^{n}$ (just take the quotient of the two quantities and expand them es products of terms). Therefore, $\sqrt[n]{n!}\geq \sqrt{\frac{n}{2}}$, and the result follows taking $N>2K^{2}$ in the definition of [[1.4 Sequences and series#^5a7f61\|unbounded limit]].
	>5) It is $kx^{k+2}-(k+1)x^{k+1}=x^{k+1}(k(x-1)-1)$. Therefore, when $X>1$ the sequence diverges. When $x<-1$, the series alternates positive and negative values, but this values grow indefinitely, so that the limit of the sequence does not exist. When $|x|<1$,  we need to find a different procedure. We start  considering $0\leq x< 1$, and noting that there is $y>0$ such that $x=(1+y)^{-1}$. Therefore, we can use the binomial formula as above to obtain 
	>		$$ (1+y)^{n}=\sum\limits_{k=0}^{n}{n\choose k} y^{n-k}\;\stackrel{k=n-2}{\geq}\;\frac{n(n-1)}{2!}y^{2} . $$
	>			It is important to note that the condition $y>0$ is necessary to obtain the inequality above. Then, we get $nx^{n}\leq \frac{2x^{2}}{(1-x)^{2}(n-1)}$, and thus the squeeze theorem for sequences implies the desired result. The case $-1<x<0$ is handled as before, but taking an overall minus sign out.{ #98a973}

2) Compute the value of the truncated geometric series associated with 
	$$ a_{n} = \left\{ \begin{matrix} a_{n}=0 & \mbox{ for } n=0,...,r-1 \\ a_{n} = x^{n} & \mbox{ for } n\geq r . \end{matrix} \right. $$
	>[!note]- Solution
	>The trick is to realize that  
	>$$ \sum_{n=0}^{+\infty}a_{n}=\sum_{n=r}^{+\infty}x^{n}= \sum_{n=0}^{+\infty}x^{n+r} = x^{r}\sum_{n=0}^{+\infty}x^{n}, $$
	>which means that the truncated geometric series is proportional to the [[1.4 Sequences and series#^bf33d9\|geometric series]], and thus its convergence, as well as its sum, can be deduced from the geometric series.

3) Determine the behavior of the arithmetic-geometric series defined by $a_{n}=nx^{n}$ (starting at $n=0$ or $n=1$).
	>[!note]- Solution
	>First of all, starting at $n=0$ or $n=1$ is irrelevant for the result. Then, once again, the series diverges when $x=1$ because $S_{k}=\sum_{n=0}^{k}a_{n}=1+2+3+\cdots +(k-1) + k= \frac{k(k+1)}{2}$.	When $k\neq 1$, we have $$ S_{k} - x S_{k} =(x + 2 x^{2} + 3 x^{3} + \cdots + k x^{k})-(x^{2} + 2 x^{3} + 3 x^{4} + k x^{k+1}) = x + x^{2} + \cdots + x^{k} -kx^{k+1} $$. 	The positive terms in the right-hand-side from the partial sum of the [[1.4 Sequences and series#^bf33d9\|geometric series]] apart from the first term. Therefore, we have	$$ (1-x)S_{k}=\frac{x^{k+1}-1}{x-1} -1 -kx^{k+1}=\frac{x-(k+1)x^{k+1} +kx^{k+2}}{1-x}  \Longrightarrow S_{k}=\frac{x-(k+1)x^{k+1} +kx^{k+2}}{(1-x)^{2}}. $$	Because of exercise 3.1.5), when $x>1$ the sequence of partial sums diverges, when $x<-1$ it does not have a limit, while it converges to $0$ when $|x|<1$. Consequently, the sum of the arithmetic-geometric series is 	$$ \sum\limits_{n=0}^{+\infty}nx^{n}=\frac{x}{(1-x)^{2}} $$ 				when $|x|<1$, while its either unbounded or undefined in the other cases.
4) Prove that, if $a_{n}=u_{n}-u_{n+1}$ for some sequence $\{u_{n}\}_{n\in\mathbb{N}}$ (**telescoping series**), then 
	$$ \sum\limits_{n=1}^{\infty}a_{n}=u_{1}-\lim_{n\rightarrow\infty}u_{n} .$$
	>[!note]- Solution
	>The partial sum of the series determined by $a_{n}$ reads 
	>	$$ S_{k}=\sum\limits_{n=1}^{k}u_{n}-u_{n+1}=u_{1}-u_{k+1}, $$
	>		and the result follows from the [[1.4 Sequences and series#^32251b\|very definition]] of the sum of a series.
5) Check the following equalities: 
	$$ \begin{split} 	1) &\qquad  \sum_{n=1}^{+\infty}\,\frac{1}{2n(n+1)}\,=\;\frac{1}{2}\\ & \\ 	2)  &\qquad  \sum_{n=0}^{+\infty}\;\frac{n}{10^{n}} \,=\;\frac{10}{81} \\ & \\ 	3)  &\qquad   \sum_{n=2}^{+\infty}\;\frac{1}{n^{2} -n}\,=\;1 \\ & \\ 	4)  &\qquad  \sum_{n=0}^{+\infty}\;\frac{1}{(n+1)(n+3)} \,=\; \frac{3}{4}\\ & \\ 	5)  &\qquad  \sum_{n=0}^{+\infty}\;\frac{2^{n+3}}{3^{n}}\,=\; 72.\end{split}$$
	>[!note]- Solution
	>1)  The result follows from exercise 3.4) above once we note that $a_{n}=\frac{1}{2}(\frac{1}{n}-\frac{1}{n+1})$.
	>2) This exercise should deserve no explication.
	>3) We note that $a_{n}= \frac{1}{n-1}-\frac{1}{n}$. Then, we perform the replacement $n=k+1$ so that
	>		$$ \sum\limits_{n=2}^{+\infty}a_{n}\rightarrow\sum\limits_{k=1}^{+\infty}a_{k} $$
	>			with $a_{k}=\frac{1}{k}-\frac{1}{k+1}$, and the result follows again from exercise 3.4) above.
	>4) We note that $a_{n}=\frac{1}{2}(\frac{1}{n+1} - \frac{1}{n+3})$, so that the replacement $k=n+1$ gives $a_{k}=\frac{1}{2}(\frac{1}{k} - \frac{1}{k+2})$. Now, we can not directly use the result of exercise 3.4) above, however, we can adapt the proof used there to this case and obtain  
	>		$$sum\limits_{k=1}^{\infty}a_{k}=\sum\limits_{k=1}u_{k}-u_{k+2}=u_{1}+u_{2}+\lim_{k\rightarrow+\infty}u_{k}, $$
	>			 from which the desired result immediately follows.
	>5) As exercise 3.5.2) above, this exercise should deserve no explanation.



# 4 Power series, trascendental functions, and Taylor expansion



1) Compute the derivatives, at all points in the maximal domain at which it makes sense, of the scalar functions determined by:
	$$ \begin{split} 1) \quad &  f(x) =\ln(x-a) \\ & \\ 2) \quad & f(x) =\ln(|x|) \\ & \\ 3) \quad & f(x)= x^{\alpha}   \\ & \\ 4) \quad & f(x) = \arcsin(x) \\ & \\ 	5) \quad & f(x) = \arccos(x) \\ & \\ 	6) \quad & f(x) = \tan(x)  \\ & \\ 	7) \quad & f(x) =\cot(x) \\ & \\ 	8) \quad & f(x) = \arctan(x) \\ & \\ 	9) \quad & f(x) =  x^{x} \\ & \\ 	10) \quad & f(x) = \sqrt{\tan(x)} \\ & \\ 	11) \quad & f(x) = \arctan\left(x^{3} - e^{x^{2}}\right) \\ & \\ 	12) \quad &  f(x)=(g(x))^{h(x)} \\ & \\	13) \quad & f(x)= \arctan\left(\frac{g(x)}{h(x)}\right)  \end{split} $$
	>[!note]- Solution
		> 1) Since $\ln(x-a)$ is the inverse function of $\mathrm{exp}(x-a)=\mathrm{e}^{x-a}$, we can use the [[1.3 Derivatives of scalar functions#^05d051\|formula for the derivative of the inverse function]] to obtain $f'(x)=\frac{1}{x-a}$. Alternatively, we can use $g(y)=\ln(y)$,  $y(x)=x-a$, and the [[1.3 Derivatives of scalar functions#^c87d27\|chain rule]].
		> 2) Because of the absolute value, we have to split the function for $x>0$ and $x<0$ (note that $x=0$ is forbidden). Once the split is done, we can proceed as in point 1) above. The result is $f'(x)=\frac{1}{x}$.
		> 3) The trick is to write $x^{\alpha}=\mathrm{e}^{\alpha\ln(x)}$ and then apply the [[1.3 Derivatives of scalar functions#^c87d27\|chain rule]]. The result is thus $f'(x)=\alpha x^{\alpha-1}$.
		> 4) Recall that the domain of $\arcsin(x)$ is $-1\leq x\leq 1$. Use the [[1.3 Derivatives of scalar functions#^05d051\|formula for the derivative of the inverse function]] to obtain $f'(x)=\frac{1}{\cos(\arcsin(x))}$. Since $-\frac{\pi}{2}<\arcsin(x)<\frac{\pi}{2}$ when $-1<x<1$, $\cos(\arcsin(x))>0$, and we can use the fact that $\cos(x)=\sqrt{1-\sin^{2}(x)}$  to obtain $f'(x)=\frac{1}{\sqrt{1-x^{2}}}$.
		> 5) Proceed as in point 4) above to get $f'(x)=-\frac{1}{\sqrt{1-x^{2}}}$.
		> 6) Use the derivative of $\sin(x)$ and $\cos(x)$ together with the [[1.3 Derivatives of scalar functions#^5d20ad\|algebraic manipulations of derivatives]] to get $f'(x)=\frac{1}{\cos^{2}(x)}$.
		> 7) Use the derivative of $\sin(x)$ and $\cos(x)$ together with the [[1.3 Derivatives of scalar functions#^5d20ad\|algebraic manipulations of derivatives]] to get $f'(x)=-\frac{1}{\sin^{2}(x)}$.
		> 8) Recalling that $\frac{1}{\cos^{2}(x)}=1 + \tan^{2}(x)$, proceed as in point 4) above to get $f'(x)=\frac{1}{1+x^{2}}$.
		> 9) Proceed as in point 3) above to get $f'(x)=x^{x}(\ln(x)+1)$.
		> 10) Use the [[1.3 Derivatives of scalar functions#^c87d27\|chain rule]] to get $f'(x)=\frac{1}{2}(\sqrt{\tan(x)}\cos^{2}(x))^{-1}$.
		> 11) Use the [[1.3 Derivatives of scalar functions#^c87d27\|chain rule]] to get $f'(x)=\frac{3x^{2} - 2x\mathrm{e}^{x^{2}}}{1+ (x^{3} - \mathrm{e}^{x^{2}})^{2}}$.
		> 12) Proceed as in point 3) above, and use the [[1.3 Derivatives of scalar functions#^c87d27\|chain rule]] to get $f'(x)=(g(x))^{h(x)}\left(h(x)\ln(g(x)) + \frac{h(x)g'(x)}{g(x)}\right)$.
		> 13) Use the [[1.3 Derivatives of scalar functions#^c87d27\|chain rule]] to get $f'(x)=\frac{g'(x)h(x)-g(x)h'(x)}{g^{2}(x)+h^{2}(x)}$.

2) Check the following limits:
	$$
	\begin{split} 
	1) \quad & \lim_{x\rightarrow 0}\, \frac{\tan(x^{2})+2x}{x+x^{2}}= 2\\ & \\
	2) \quad & \lim_{x\rightarrow 0}\,\frac{\mathrm{e}^{x} - x - \cos(x)}{\sin(x^{2})} = 1 \\ & \\
	3) \quad & \lim_{x\rightarrow +\infty}\,\left(1 + \frac{1}{x}\right)^{x}= \mathrm{e}  \\ & \\
	4) \quad & \lim_{x\rightarrow +\infty}\, \frac{\left(1 + \frac{1}{x}\right)^{x^{2}}}{\mathrm{e}^{x}} = \mathrm{e}^{-\frac{1}{2}}\\ & \\
	5) \quad &  
	\end{split}
	$$
	>	[!note]- Solution
	>	1) We first write
	>		$$ \frac{\tan(x^{2})+2x}{x+x^{2}}=\frac{\sin(x^{2})}{x(1+x)\cos(x^{2})} + \frac{2}{(1+x)},$$
	>		from which it is clear that the second term in the right-hand-side will not give us problems. Then, we note that
	>			$$ \frac{\sin(x^{2})}{x(1+x)\cos(x^{2})}=\frac{x\sin(x^{2})}{x^{2}(1+x)\cos(x^{2})},$$
	>		so that we can use the limit
	>			$$ \lim_{y\rightarrow 0}\frac{\sin(y)}{y}=1$$
	>		together with the [[1.2 Limits of scalar functions#^c8052c\|compostion of limits]] to verify the claimed result.
	>	2) Since the first order expansion of $\sin(x^{2})$ already contain $x^{2}$, we expand $\mathrm{e}^{x}$ and $\cos(x)$ up to the second order. Then, the result follows from a direct computation taking into account [[1.5 Power series, trascendental functions, and Taylor series#^113a5b\|the property of remainder]].
	>	3) Since the limit is for $x\rightarrow+\infty$, we can not use Taylor's theorem. Analogously, we can not apply L'Hôpital's rule because we do not have a quotient of functions. However, we can exploit a trick. We start writing $(1+\frac{1}{x})^{x}=\mathrm{e}^{x\ln(1+\frac{1}{x})}$. Then, we introduce the auxiliary variable $y=(1+\frac{1}{x})$, so that $x=\frac{1}{1-x}$, and thus $(1+\frac{1}{x})^{x}=\mathrm{e}^{\frac{\ln(y)}{y-1}}$. Moreover, we have $y\rightarrow 1^{+}$ when $x\rightarrow+\infty$, so that
	>		$$ \lim_{x\rightarrow +\infty} \,(1+\frac{1}{x})^{x}=\mathrm{e}^{\frac{\ln(y)}{y-1}} = \mathrm{e}^{\lim_{y\rightarrow 1^{+}}\,\frac{\ln(y)}{y-1}}, $$
	>			where we applied the [[1.2 Limits of scalar functions#^c8052c\|limit of composite functions]] to obtain the last equality. We can now apply L'Hôpital's and verify the limit. 
	>		4) To verify the limit, it suffices to follow the steps in point 3). 

4) Use Taylor's theorem to estimate:
	1) $\mathrm{e}^{0.2}$ with an error smaller than $0.0005$;
	2) $\sin(0.1)$ with an error smaller than $0.0005$.
	
	>[!note]- Solution 


# 5 Global extrema of scalar functions

1) Study the global extrema of the following functions:
	$$
	\begin{split}
	1) \quad & f(x)\,=\; x + \frac{1}{x} \\ & \\
	2) \quad & f(x)\,=\; \frac{x^{2}}{1+x} \\ & \\
	3) \quad & f(x)\,=\;  x^{2}\,\left(2+x\right)^{\frac{1}{3}}\\ & \\
	4) \quad & f(x)\,=\; |x - 3| + |2x + 1|  \\ & \\
	5) \quad & f(x)\,=\;  x + \cos(2x) \\ & \\
	6) \quad & f(x)\,=\;  \left\{\begin{matrix} 2 - 2x -x^{2} & \quad -2\leq x\leq 0 \\ |x-2| & \quad  0<x<3 \\ \frac{1}{3}\left(x-2\right)^{2} & \quad  3\leq x \leq 4 \end{matrix}\right.\\ & \\
	7) \quad & f(x)\,=\; \left\{\begin{matrix} x^{2} +1 & \quad  -2\leq x < 1 \\ 5 + 2x -x^{2}& \quad  -1\leq x\leq 3 \\ x-1 & \quad  3< x < 6 \end{matrix}\right.  \\ & \\
	8) \quad & f(x)\,=\;  \left\{\begin{matrix} \frac{3-x^{2}}{2} & \quad  x < 1 \\ \frac{1}{x} & \quad  -1\leq x    \end{matrix}\right.\\ & \\
	9) \quad & f(x)\,=\; 1 - (x-1)^{\frac{1}{3}} \\ & \\
	10) \quad & f(x)\,=\; \sqrt{x} - \frac{1}{\sqrt{x}} \\ & \\
	\end{split}
	$$